It was time to review the architecture of my project. I utilized EC2 instances, ELB Auto Scaling from Beanstack, S3, RDS, Elastic Cache, ActiveMQ, Route 53, and CloudFront. Users accessed my URL, which was resolved to an endpoint by Amazon Route 53. This endpoint was part of the Amazon CloudFront content delivery network, caching various elements to serve a global audience efficiently.

From there, the request was redirected to the Application Load Balancer, integrated with my Elastic Beanstack. The Application Load Balancer then forwarded the request to my EC2 instance, which was part of an Auto Scaling group. On these instances, the Tomcat application service was running, all within the Elastic Beanstack environment. Amazon CloudWatch alarms monitored the Auto Scaling group, scaling out and scaling in based on demand.

My artifacts were stored in an S3 bucket, and I could deploy the latest artifact with a simple click. The entire frontend was managed by Beanstack. For the backend, instead of RabbitMQ, I used Amazon MQ. Instead of deploying Memcache on EC2 instances, I utilized the Elastic Cache service. Additionally, rather than running the database on EC2 instances, I employed Amazon RDS.

When a user accessed the endpoint, Amazon CloudFront directed the request to the Application Load Balancer within Beanstack. This load balancer then forwarded the request to instances in the Auto Scaling group. Amazon CloudWatch alarms monitored all these activities. The artifacts were stored in the S3 bucket. For the backend, it accessed Amazon MQ, Elastic Cache, and Amazon RDS services.